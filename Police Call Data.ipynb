{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Data is in CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1 - Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the dataset. For this demo we'll load just one dataset but you could load all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also load call_types for better definitions\n",
    "call_types = pd.read_csv(\n",
    "     \"assets/pd_cfs_calltypes_datasd.csv\",\n",
    "     keep_default_na=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Helper Scripts we built to Make sure that data was consistent on upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_floats_to_ints(val):\n",
    "    try:\n",
    "        return int(float(val))\n",
    "\n",
    "    except (TypeError, ValueError):\n",
    "        return val\n",
    "\n",
    "\n",
    "def strip_priority(val):\n",
    "    try:\n",
    "        return convert_floats_to_ints(val[0])\n",
    "\n",
    "    except (TypeError, ValueError, IndexError):\n",
    "        return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"assets/pd_calls_for_service_2021_datasd.csv\"\n",
    "df = pd.read_csv(\n",
    "                csv_file,\n",
    "                keep_default_na=False,\n",
    "                parse_dates=[\"date_time\"],\n",
    "            )\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's See What We can Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_call_type = pd.merge(df, call_types[['call_type','description']], on=\"call_type\", how=\"left\").fillna('').drop_duplicates('incident_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last line is a little ugly let's explain\n",
    "\n",
    "`pd.merge` - combine the our `call types` data with our actual stop data.\n",
    "\n",
    "`.fillna` - creates consistency with the rest of our empty fields (replacing NaN/NA values)\n",
    "\n",
    "`.drop_duplicates` - not sure why duplicates are created but this is common and I discovered that removing the duplicates on the `incident_num` (unique for each call) seems to resolve the issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we make sense of this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're goign to create a sorting help function\n",
    "\n",
    "def sort_group(group):\n",
    "    return sorted(group, key=lambda x:len(x[1]), reverse=True)\n",
    "\n",
    "df_w_call_type[\"beat\"] = df_w_call_type[\"beat\"].apply(convert_floats_to_ints)\n",
    "df_w_call_type[\"priority\"] = df_w_call_type[\"priority\"].apply(strip_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calls per Beat in 2021\n",
    "\n",
    "grouped_beats = sort_group(df_w_call_type.groupby('beat'))\n",
    "\n",
    "for beat, group in grouped_beats[:5]:\n",
    "    num_of_calls = len(group)\n",
    "    print(f\"{beat=}, {num_of_calls=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beat 523 Calls\n",
    "\n",
    "beat_523 = df_w_call_type[df_w_call_type.beat==523]\n",
    "beat_523.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busiest Intersections for Beat 523\n",
    "\n",
    "intersections = beat_523[beat_523.address_road_intersecting != '']\n",
    "grouped_beats = sort_group(intersections.groupby(['address_road_primary', 'address_road_intersecting']))\n",
    "\n",
    "for intersection, group in grouped_beats[:5]:\n",
    "    num_of_calls = len(group)\n",
    "    print(f\"{intersection=}, {num_of_calls=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_523['priority'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_523['description'].value_counts()[:5].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is great but a little narrow \n",
    "## Let's Load Data into Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Though?\n",
    "\n",
    "- Offload Storage and Processing to Server\n",
    "- Visualization Tools (Kibana Lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Look at our Traditional Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# Load Client\n",
    "client = Elasticsearch(\n",
    "    hosts=[os.environ[\"ELASTICSEARCH_HOST\"]],  # for local instance\n",
    ")\n",
    "\n",
    "# upload data to Elasticsearch (because we have the data loaded into pandas we can just export the dataframe to json)\n",
    "\n",
    "bulk(client=client, index='test_2021_index', actions=df.to_dict('records'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool Data is in and we can work with it in Kibana\n",
    "\n",
    "# But what did all the work (pandas)\n",
    "\n",
    "`# upload data to Elasticsearch (because we have the data loaded into pandas we can just export the dataframe to json)`\n",
    "\n",
    "## How do we work with the data in python if we start with the data in Elasticsearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = client.search(\n",
    "    index=\"test_2021_index\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match_all\": {}\n",
    "       }\n",
    "    })['hits']['hits']\n",
    "\n",
    "new_df = pd.DataFrame([x['_source'] for x in results])\n",
    "new_df.head()\n",
    "\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we make changes to this data?\n",
    "\n",
    "[Let's check this](http://jays-mac-mini-3.local:5601/app/dashboards#/view/b5c671c0-3e71-11eb-b5a2-43487ca632dc?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:now-8y,to:now))&_a=(description:'',filters:!(),fullScreenMode:!f,options:(hidePanelTitles:!f,useMargins:!t),panels:!((embeddableConfig:(),gridData:(h:26,i:'8ad5d19f-c5e0-41c9-89b4-03c6a1e8b09a',w:12,x:0,y:0),id:'13720c30-3f35-11eb-b5a2-43487ca632dc',panelIndex:'8ad5d19f-c5e0-41c9-89b4-03c6a1e8b09a',type:visualization,version:'7.10.0'),(embeddableConfig:(hiddenLayers:!(),isLayerTOCOpen:!f,mapCenter:(lat:32.82517,lon:-116.91398,zoom:8.11),openTOCDetails:!()),gridData:(h:14,i:'40a2aa29-3a4f-4bc6-b5fc-65f97926ede3',w:32,x:12,y:0),id:'4f55ff10-3f33-11eb-b5a2-43487ca632dc',panelIndex:'40a2aa29-3a4f-4bc6-b5fc-65f97926ede3',type:map,version:'7.10.0'),(embeddableConfig:(),gridData:(h:12,i:ea97ada1-6535-42f9-8881-2d616d70a134,w:10,x:23,y:14),id:a939c2c0-3e9b-11eb-b5a2-43487ca632dc,panelIndex:ea97ada1-6535-42f9-8881-2d616d70a134,type:visualization,version:'7.10.0'),(embeddableConfig:(),gridData:(h:12,i:'9fdc5b9f-5f85-4aef-a066-f74c1df2b5cf',w:11,x:33,y:14),id:'1460f8c0-3e74-11eb-b5a2-43487ca632dc',panelIndex:'9fdc5b9f-5f85-4aef-a066-f74c1df2b5cf',type:visualization,version:'7.10.0'),(embeddableConfig:(),gridData:(h:13,i:e18eb168-dc4f-4bb7-83a3-ccb262d34f85,w:12,x:0,y:26),id:c3b65300-3f33-11eb-b5a2-43487ca632dc,panelIndex:e18eb168-dc4f-4bb7-83a3-ccb262d34f85,type:visualization,version:'7.10.0'),(embeddableConfig:(),gridData:(h:13,i:'3c0c0e0f-b33c-4971-a8bf-8a2a7fc2c63a',w:32,x:12,y:26),id:f68052b0-3e9b-11eb-b5a2-43487ca632dc,panelIndex:'3c0c0e0f-b33c-4971-a8bf-8a2a7fc2c63a',type:lens,version:'7.10.0'),(embeddableConfig:(),gridData:(h:11,i:'75a467b0-b343-44dd-a547-d144a9ef629e',w:44,x:0,y:39),id:'7f47ea40-3e74-11eb-b5a2-43487ca632dc',panelIndex:'75a467b0-b343-44dd-a547-d144a9ef629e',type:lens,version:'7.10.0'),(embeddableConfig:(),gridData:(h:15,i:'01918722-445d-4dbd-ace3-0b5f488afd5b',w:44,x:0,y:50),id:fd2eca90-3e75-11eb-b5a2-43487ca632dc,panelIndex:'01918722-445d-4dbd-ace3-0b5f488afd5b',type:lens,version:'7.10.0')),query:(language:kuery,query:''),timeRestore:!f,title:'PD%20Calls%20Overtime',viewMode:edit))\n",
    "\n",
    "Yes, but...\n",
    "In order to do this we need to make the changes in the dataframe and then re-upload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's talk about [Eland](https://eland.readthedocs.io/en/7.10.1b1/#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eland is Elasticsearch data in a Dataframe view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's like\n",
    "\n",
    "```python\n",
    "results = client.search(\n",
    "    body={\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"match_all\": {}\n",
    "       }\n",
    "    })['hits']['hits']\n",
    "\n",
    "new_df = pd.DataFrame([x['_source'] for x in results])\n",
    "```\n",
    "\n",
    "but `new_df` is connected to your Elasticsearch instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eland\n",
    "\n",
    "# all things Elasticsearch use 'es_' as a prefix\n",
    "\n",
    "edf = eland.DataFrame(es_client=client, es_index_pattern=\"test_2021_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebeat_523 = edf[edf.beat==523]\n",
    "ebeat_523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared to our original\n",
    "beat_523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_523['description'].value_counts()[:5].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_523['description'].value_counts()[:5].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_pd_data = eland.DataFrame(es_client=client, es_index_pattern=\"pd_calls_for_service_*\")\n",
    "sd_pd_data['description'].value_counts()[:5].plot(kind=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
